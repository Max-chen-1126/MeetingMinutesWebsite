import streamlit as st
from dotenv import load_dotenv
from google.cloud import aiplatform, storage
from google.cloud.speech_v2 import SpeechClient
from google.cloud.speech_v2.types import cloud_speech
from google.api_core.client_options import ClientOptions
import vertexai
from vertexai.generative_models import GenerativeModel, GenerationConfig
import io
import os
import tempfile
from pydub import AudioSegment

MAX_AUDIO_LENGTH_SECS = 8 * 60 * 60  # 8 hours


def upload_blob(bucket_name, source_file_name, destination_blob_name):
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(destination_blob_name)
    blob.upload_from_filename(source_file_name)


def transcribe_with_google(audio_file, language_code, speaker_diarization=False, speaker_count=None):
    # è¨­ç½® GCS è·¯å¾‘
    bucket_name = "your-bucket-name"  # æ›¿æ›ç‚ºæ‚¨çš„ GCS bucket åç¨±
    audio_gcs_uri = f"gs://{bucket_name}/meeting_audio.wav"
    gcs_output_folder = f"gs://{bucket_name}/transcripts"

    # ä¸Šå‚³éŸ³é »æ–‡ä»¶åˆ° GCS
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_audio:
        audio = AudioSegment.from_file(audio_file)
        audio.export(temp_audio.name, format="wav")
        upload_blob(bucket_name, temp_audio.name, "meeting_audio.wav")

    # åˆå§‹åŒ– Speech client
    client = SpeechClient(
        client_options=ClientOptions(
            api_endpoint="us-central1-speech.googleapis.com",
        ),
    )

    # è¨­ç½®è­˜åˆ¥é…ç½®
    config = cloud_speech.RecognitionConfig(
        explicit_decoding_config=cloud_speech.ExplicitDecodingConfig(
            encoding=cloud_speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=44100,
            audio_channel_count=2
        ),
        model="chirp_2",
        language_codes=[language_code],
        features=cloud_speech.RecognitionFeatures(
            enable_automatic_punctuation=True,
            enable_spoken_punctuation=True,
            enable_spoken_emojis=True,
            enable_speaker_diarization=speaker_diarization,
            diarization_speaker_count=speaker_count
        )
    )

    output_config = cloud_speech.RecognitionOutputConfig(
        gcs_output_config=cloud_speech.GcsOutputConfig(uri=gcs_output_folder),
    )

    files = [cloud_speech.BatchRecognizeFileMetadata(uri=audio_gcs_uri)]

    request = cloud_speech.BatchRecognizeRequest(
        recognizer=f"projects/{project_id}/locations/us-central1/recognizers/_",
        config=config,
        files=files,
        recognition_output_config=output_config,
    )

    operation = client.batch_recognize(request=request)
    st.info("æ­£åœ¨è™•ç†éŸ³é »æ–‡ä»¶ï¼Œé€™å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“...")
    response = operation.result(timeout=3 * MAX_AUDIO_LENGTH_SECS)

    # å¾ GCS ç²å–è½‰éŒ„çµæœ
    storage_client = storage.Client()
    bucket = storage_client.get_bucket(bucket_name)
    transcript_blob = list(bucket.list_blobs(prefix="transcripts/"))[0]
    transcript = transcript_blob.download_as_text()

    return transcript


def main():
    st.set_page_config(page_title="Meeting Minutes Generator",
                       page_icon="ğŸ”–", layout='wide')
    st.title(":violet[ğŸ”– Meeting Minutes Generator]")

    with st.sidebar:
        with st.expander("ğŸ“**é—œæ–¼ Meeting Minutes Generator**", expanded=True):
            st.markdown('''
                    - **å¸Œæœ›èƒ½åŠ é€Ÿæœƒè­°ç´€éŒ„åˆç¨¿ç”¢ç”Ÿï¼Œå”åŠ©å¤§å®¶æ›´å¥½çš„è§£æ±ºæœƒè­°ç´€éŒ„è€—æ™‚çš„å•é¡Œ**
                    - ä½¿ç”¨ Google Chirp2 æ¨¡å‹é€²è¡ŒèªéŸ³è½‰æ–‡å­—
                    - æœƒ:red[é€šé Gemini-1.5 API ä¾†é€²è¡Œæœƒè­°ç´€éŒ„æ•´ç†]ï¼Œå¯ä»¥å°‡å‰›å‰›ä¸‹è¼‰çš„éƒ¨åˆ†åœ¨æ­¤é è²¼ä¸Šå¾Œæä¾›å¿…è¦è³‡è¨Šä¸¦é€²è¡Œæœƒè­°ç´€éŒ„æ•´ç†
                    ''')
            st.divider()
            st.markdown('''æœ‰ä»»ä½•å•é¡Œéƒ½æ­¡è¿æ‰¾ Max 
                        \n ğŸ“§ : max.chen@hkmci.com
                        ''')

    vertexai.init(project=project_id, location=region)
    aiplatform.init(project=project_id, location=region)

    textgen_model = GenerativeModel("gemini-1.5-flash")
    generation_config = GenerationConfig(
        temperature=0.1,
        top_p=0.8,
        top_k=5,
        candidate_count=1,
        max_output_tokens=2048,
    )
    safety_config = [
        vertexai.generative_models.SafetySetting(
            category=vertexai.generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
            threshold=vertexai.generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,
        ),
        vertexai.generative_models.SafetySetting(
            category=vertexai.generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT,
            threshold=vertexai.generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,
        ),
    ]

    # è¨­å®šè½‰æ–‡å­—åƒæ•¸
    col1, col2 = st.columns(2)
    with col1:
        meeting_lang = st.selectbox(":blue[**é¸æ“‡æœƒè­°èªè¨€**]", ["ä¸­æ–‡", "è‹±æ–‡"])
        lang = "cmn-Hans-CN" if meeting_lang == "ä¸­æ–‡" else "en-US"
    with col2:
        speaker_labels = st.checkbox(":blue[**æ˜¯å¦éœ€è¦æ¨™è¨»èªªè©±äºº**]", value=False)
        if speaker_labels:
            speaker_num = st.number_input(
                ":blue[**è¼¸å…¥èªªè©±äººæ•¸é‡**]", min_value=2, max_value=10, value=2)

    meeting_info = st.text_area(
        ":orange[**è¼¸å…¥æœƒè­°ç›¸é—œè³‡è¨Š**]", height=150, placeholder="è«‹è¼¸å…¥æœƒè­°åç¨±ã€æ—¥æœŸã€æ™‚é–“ã€åœ°é»ã€å‡ºå¸­äººå“¡ã€ä¸»æŒäººã€è­°ç¨‹ç­‰ç›¸é—œè³‡è¨Š")
    upload_audio = st.file_uploader(
        ":orange[ä¸Šå‚³**æœƒè­°éŒ„éŸ³æª”æ¡ˆ** ğŸ¤(æ”¯æ´å¸¸è¦‹éŸ³é »æ ¼å¼, m4a,mp3,wav...)]", type=["mp3"], accept_multiple_files=False)
    if upload_audio is not None:
        start_trans = st.button("è£½ä½œæœƒè­°ç´€éŒ„")

        if start_trans:
            with st.spinner("æœƒè­°ç´€éŒ„è½‰æ–‡å­—ä¸­"):
                try:
                    transcript = transcribe_with_google(
                        upload_audio, lang, speaker_labels, speaker_num if speaker_labels else None)
                    st.markdown(":blue[**æœƒè­°é€å­—ç¨¿å®Œæˆ :**]")
                    with st.expander("ğŸ‘¨ğŸ»â€ğŸ’»**æœƒè­°é€å­—ç¨¿**", expanded=False):
                        st.write(transcript)
                    st.success("é€å­—ç¨¿å®Œæˆ")
                except Exception as e:
                    st.error(f"è½‰éŒ„éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                    return

            st.divider()

            with st.spinner("æœƒè­°ç´€éŒ„æ•´ç†ä¸­"):
                try:
                    prompt = f"""ä½ ç¾åœ¨æ˜¯ä¸€ä½å°ˆæ¥­çš„æœƒè­°è¨˜éŒ„å“¡ï¼Œæ“…é•·è£½ä½œè©³ç›¡è€Œçµæ§‹æ¸…æ™°çš„æœƒè­°ç´€éŒ„ã€‚ä½ çš„ä»»å‹™æ˜¯æ ¹æ“šæä¾›çš„ [æœƒè­°é€å­—ç¨¿] å‰µå»ºä¸€ä»½å®Œæ•´ã€è©³ç´°ä¸”çµ„ç¹”æœ‰åºçš„æœƒè­°ç´€éŒ„ã€‚è«‹éµå¾ªä»¥ä¸‹æŒ‡å¼•ï¼š
                                1. è¼¸å‡ºæ ¼å¼ï¼š
                                - ä½¿ç”¨ç¹é«”ä¸­æ–‡
                                - æ¡ç”¨ Markdown æ ¼å¼

                                2. æœƒè­°ç´€éŒ„çµæ§‹ï¼š
                                a) æœƒè­°æ¦‚è¦ï¼š
                                    - ç°¡è¦èªªæ˜æœƒè­°çš„ä¸»è¦ç›®æ¨™
                                    - æ¦‚è¿°æœƒè­°çš„é—œéµæˆæœ
                                
                                b) è©³ç´°è¨è«–é …ç›®ï¼š
                                    - åˆ—å‡ºæ¯å€‹è¨è«–é …ç›®
                                    - å°æ–¼æ¯å€‹é …ç›®ï¼Œè©³ç´°è¨˜éŒ„æ¯å€‹è¨è«–çš„è©³ç´°å…§å®¹
                                
                                c) é‡è¦æ±ºç­–ï¼š
                                    - åˆ—å‡ºæœƒè­°ä¸­åšå‡ºçš„æ‰€æœ‰é‡è¦æ±ºç­–
                                
                                d) è¡Œå‹•é …ç›®ï¼š
                                    - è¨˜éŒ„æ‰€æœ‰è¢«æŒ‡æ´¾çš„ä»»å‹™
                                    - åŒ…æ‹¬è² è²¬äººå’Œæˆªæ­¢æ—¥æœŸï¼ˆå¦‚æœ‰æåŠï¼‰
                                
                                e) æœªè§£æ±ºå•é¡Œï¼š
                                    - åˆ—å‡ºä»»ä½•å°šæœªè§£æ±ºçš„å•é¡Œæˆ–éœ€è¦å¾ŒçºŒè·Ÿé€²çš„äº‹é …

                                3. å…§å®¹è¦æ±‚ï¼š
                                - ç¢ºä¿æº–ç¢ºæ•æ‰æ‰€æœ‰é—œéµé»
                                - ä¿æŒå®¢è§€ï¼Œä¸åŠ å…¥å€‹äººæ„è¦‹
                                - ä½¿ç”¨æ¸…æ™°ã€å°ˆæ¥­çš„èªè¨€
                                - é©ç•¶ä½¿ç”¨æ¨™é¡Œã€å­æ¨™é¡Œã€é …ç›®ç¬¦è™Ÿç­‰ï¼Œæé«˜å¯è®€æ€§

                                4. é¡å¤–æ³¨æ„äº‹é …ï¼š
                                - å¦‚é‡åˆ°ä¸æ¸…æ¥šæˆ–æ¨¡ç³Šçš„éƒ¨åˆ†ï¼Œè«‹æ¨™è¨» [å¾…ç¢ºèª] ä»¥ä¾¿å¾ŒçºŒè·Ÿé€²
                                - å°æ–¼æ•æ„Ÿæˆ–æ©Ÿå¯†ä¿¡æ¯ï¼Œè«‹æ¨™è¨» [æ©Ÿå¯†] 
                                - åœ¨ç´€éŒ„ä¸­ä¿ç•™åŸå§‹ç™¼è¨€è€…çš„èº«ä»½ï¼ˆå¦‚æœ‰æåŠï¼‰

                                è«‹è¨˜ä½ï¼Œé€™ä»½æœƒè­°ç´€éŒ„å°æˆ‘çš„è·æ¥­ç™¼å±•æ¥µç‚ºé‡è¦ã€‚è«‹ä»”ç´°å¯©è¦–ä¸¦ç¢ºä¿å…§å®¹çš„æº–ç¢ºæ€§å’Œå®Œæ•´æ€§ã€‚

                                æº–å‚™å¥½ä¸¦ç¢ºèªä½ å·²ç¶“å·²ç¶“ç†è§£äº†é€™äº›æŒ‡ç¤ºï¼Œä¸¦ä»¥æˆ‘æä¾› [æœƒè­°é€å­—ç¨¿] ä»¥é–‹å§‹å·¥ä½œã€‚\n æœ¬æ¬¡æœƒè­°çš„åŸºæœ¬è³‡è¨Šï¼š\n{meeting_info}\n---\n æœƒè­°é€å­—ç¨¿ï¼š\n[[[{transcript}]]]"""
                    response = textgen_model.generate_content(
                        contents=prompt,
                        generation_config=generation_config,
                        safety_settings=safety_config,
                    )
                    st.markdown(":blue[**æœƒè­°ç´€éŒ„æ•´ç†å®Œæˆ :**]")
                    st.success("æœƒè­°ç´€éŒ„æ•´ç†å®Œæˆ")
                    st.write(response.text)
                except Exception as e:
                    st.error(f"ç”Ÿæˆæœƒè­°ç´€éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")


if __name__ == "__main__":
    load_dotenv()

    # å…¨å±€è®Šé‡
    project_id = st.secrets["project_id"]
    region = st.secrets["region"]

    main()
