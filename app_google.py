import streamlit as st
from dotenv import load_dotenv
from google.cloud import aiplatform, storage
from google.cloud.speech_v2 import SpeechClient
from google.cloud.speech_v2.types import cloud_speech
from google.api_core.client_options import ClientOptions
import vertexai
from vertexai.generative_models import GenerativeModel, GenerationConfig
import io
import os
import tempfile
from pydub import AudioSegment

MAX_AUDIO_LENGTH_SECS = 8 * 60 * 60  # 8 hours

def upload_blob(bucket_name, source_file_name, destination_blob_name):
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(destination_blob_name)
    blob.upload_from_filename(source_file_name)

def transcribe_with_google(audio_file, language_code, speaker_diarization=False, speaker_count=None):
    # è¨­ç½® GCS è·¯å¾‘
    bucket_name = "your-bucket-name"  # æ›¿æ›ç‚ºæ‚¨çš„ GCS bucket åç¨±
    audio_gcs_uri = f"gs://{bucket_name}/meeting_audio.wav"
    gcs_output_folder = f"gs://{bucket_name}/transcripts"

    # ä¸Šå‚³éŸ³é »æ–‡ä»¶åˆ° GCS
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_audio:
        audio = AudioSegment.from_file(audio_file)
        audio.export(temp_audio.name, format="wav")
        upload_blob(bucket_name, temp_audio.name, "meeting_audio.wav")

    # åˆå§‹åŒ– Speech client
    client = SpeechClient(
        client_options=ClientOptions(
            api_endpoint="us-central1-speech.googleapis.com",
        ),
    )

    # è¨­ç½®è­˜åˆ¥é…ç½®
    config = cloud_speech.RecognitionConfig(
        explicit_decoding_config=cloud_speech.ExplicitDecodingConfig(
            encoding=cloud_speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=44100,
            audio_channel_count=2
        ),
        model="chirp_2",
        language_codes=[language_code],
        features=cloud_speech.RecognitionFeatures(
            enable_automatic_punctuation=True,
            enable_spoken_punctuation=True,
            enable_spoken_emojis=True,
            enable_speaker_diarization=speaker_diarization,
            diarization_speaker_count=speaker_count
        )
    )

    output_config = cloud_speech.RecognitionOutputConfig(
        gcs_output_config=cloud_speech.GcsOutputConfig(uri=gcs_output_folder),
    )

    files = [cloud_speech.BatchRecognizeFileMetadata(uri=audio_gcs_uri)]

    request = cloud_speech.BatchRecognizeRequest(
        recognizer=f"projects/{project_id}/locations/us-central1/recognizers/_",
        config=config,
        files=files,
        recognition_output_config=output_config,
    )

    operation = client.batch_recognize(request=request)
    st.info("æ­£åœ¨è™•ç†éŸ³é »æ–‡ä»¶ï¼Œé€™å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“...")
    response = operation.result(timeout=3 * MAX_AUDIO_LENGTH_SECS)

    # å¾ GCS ç²å–è½‰éŒ„çµæœ
    storage_client = storage.Client()
    bucket = storage_client.get_bucket(bucket_name)
    transcript_blob = list(bucket.list_blobs(prefix="transcripts/"))[0]
    transcript = transcript_blob.download_as_text()

    return transcript

def main():
    st.set_page_config(page_title="Meeting Minutes Generator",
                       page_icon="ğŸ”–", layout='wide')
    st.title(":violet[ğŸ”– Meeting Minutes Generator]")
    
    with st.sidebar:
        with st.expander("ğŸ“**é—œæ–¼ Meeting Minutes Generator**", expanded=True):
            st.markdown('''
                    - **å¸Œæœ›èƒ½åŠ é€Ÿæœƒè­°ç´€éŒ„åˆç¨¿ç”¢ç”Ÿï¼Œå”åŠ©å¤§å®¶æ›´å¥½çš„è§£æ±ºæœƒè­°ç´€éŒ„è€—æ™‚çš„å•é¡Œ**
                    - ä½¿ç”¨ Google Chirp2 æ¨¡å‹é€²è¡ŒèªéŸ³è½‰æ–‡å­—
                    - æœƒ:red[é€šé Gemini-1.5 API ä¾†é€²è¡Œæœƒè­°ç´€éŒ„æ•´ç†]ï¼Œå¯ä»¥å°‡å‰›å‰›ä¸‹è¼‰çš„éƒ¨åˆ†åœ¨æ­¤é è²¼ä¸Šå¾Œæä¾›å¿…è¦è³‡è¨Šä¸¦é€²è¡Œæœƒè­°ç´€éŒ„æ•´ç†
                    ''')
            st.divider()
            st.markdown('''æœ‰ä»»ä½•å•é¡Œéƒ½æ­¡è¿æ‰¾ Max 
                        \n ğŸ“§ : max.chen@hkmci.com
                        ''')
    
    vertexai.init(project=project_id, location=region)
    aiplatform.init(project=project_id, location=region)
    
    textgen_model = GenerativeModel("gemini-1.5-flash")
    generation_config = GenerationConfig(
        temperature=0.1,
        top_p=0.8,
        top_k=5,
        candidate_count=1,
        max_output_tokens=2048,
    )
    safety_config = [
        vertexai.generative_models.SafetySetting(
            category=vertexai.generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
            threshold=vertexai.generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,
        ),
        vertexai.generative_models.SafetySetting(
            category=vertexai.generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT,
            threshold=vertexai.generative_models.HarmBlockThreshold.BLOCK_ONLY_HIGH,
        ),
    ]
    
    # è¨­å®šè½‰æ–‡å­—åƒæ•¸
    col1,col2 = st.columns(2)
    with col1:
        meeting_lang = st.selectbox(":blue[**é¸æ“‡æœƒè­°èªè¨€**]", ["ä¸­æ–‡", "è‹±æ–‡"])
        lang = "cmn-Hans-CN" if meeting_lang == "ä¸­æ–‡" else "en-US"
    with col2:
        speaker_labels = st.checkbox(":blue[**æ˜¯å¦éœ€è¦æ¨™è¨»èªªè©±äºº**]", value=False)
        if speaker_labels:
            speaker_num = st.number_input(":blue[**è¼¸å…¥èªªè©±äººæ•¸é‡**]", min_value=2, max_value=10, value=2)
    
    meeting_info = st.text_area(":orange[**è¼¸å…¥æœƒè­°ç›¸é—œè³‡è¨Š**]", height=150, placeholder="è«‹è¼¸å…¥æœƒè­°åç¨±ã€æ—¥æœŸã€æ™‚é–“ã€åœ°é»ã€å‡ºå¸­äººå“¡ã€ä¸»æŒäººã€è­°ç¨‹ç­‰ç›¸é—œè³‡è¨Š")
    upload_audio = st.file_uploader(":orange[ä¸Šå‚³**æœƒè­°éŒ„éŸ³æª”æ¡ˆ** ğŸ¤(æ”¯æ´å¸¸è¦‹éŸ³é »æ ¼å¼, m4a,mp3,wav...)]", type=["m4a","mp3","wav"],accept_multiple_files=False)
    if upload_audio is not None:
        start_trans = st.button("è£½ä½œæœƒè­°ç´€éŒ„")
        
        if start_trans:
            with st.spinner("æœƒè­°ç´€éŒ„è½‰æ–‡å­—ä¸­"):
                try:
                    transcript = transcribe_with_google(upload_audio, lang, speaker_labels, speaker_num if speaker_labels else None)
                    st.markdown(":blue[**æœƒè­°é€å­—ç¨¿å®Œæˆ :**]")
                    with st.expander("ğŸ‘¨ğŸ»â€ğŸ’»**æœƒè­°é€å­—ç¨¿**", expanded=False):
                        st.write(transcript)
                    st.success("é€å­—ç¨¿å®Œæˆ")
                except Exception as e:
                    st.error(f"è½‰éŒ„éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                    return

            st.divider()    
            
            with st.spinner("æœƒè­°ç´€éŒ„æ•´ç†ä¸­"):
                try:
                    prompt = f"""æ‚¨çš„ä»»å‹™æ˜¯æŸ¥çœ‹æä¾›çš„æœƒè­°è¨˜éŒ„ä¸¦å‰µå»ºä¸€å€‹ç°¡æ½”çš„æ‘˜è¦ä¾†æ•ç²åŸºæœ¬ä¿¡æ¯ï¼Œé‡é»é—œæ³¨æœƒè­°æœŸé–“çš„é—œéµè¦é»å’Œè¡Œå‹•é …ç›®ã€‚ä½¿ç”¨æ¸…æ™°ã€å°ˆæ¥­çš„èªè¨€ï¼Œä¸¦ä½¿ç”¨æ¨™é¡Œã€å‰¯æ¨™é¡Œå’Œé …ç›®ç¬¦è™Ÿç­‰é©ç•¶çš„æ ¼å¼ä»¥é‚è¼¯æ–¹å¼çµ„ç¹”æ‘˜è¦ã€‚ç¢ºä¿æ‘˜è¦æ˜“æ–¼ç†è§£ï¼Œä¸¦å°æœƒè­°å…§å®¹æä¾›å…¨é¢è€Œç°¡æ½”çš„æ¦‚è¿°ï¼Œç‰¹åˆ¥æ³¨é‡æ˜ç¢ºæŒ‡å‡ºæ¯å€‹è¡Œå‹•é …ç›®ã€‚ ---\n æœ¬æ¬¡æœƒè­°çš„åŸºæœ¬è³‡è¨Šï¼š\n{meeting_info}\n---\n æœƒè­°éŒ„éŸ³è½‰æˆé€å­—ç¨¿ï¼š\n{transcript}"""
                    response = textgen_model.generate_content(
                        contents=prompt,
                        generation_config=generation_config,
                        safety_settings=safety_config,
                    )
                    st.markdown(":blue[**æœƒè­°ç´€éŒ„æ•´ç†å®Œæˆ :**]")
                    st.success("æœƒè­°ç´€éŒ„æ•´ç†å®Œæˆ")
                    st.write(response.text)
                except Exception as e:
                    st.error(f"ç”Ÿæˆæœƒè­°ç´€éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

if __name__ == "__main__":
    load_dotenv()
    
    # å…¨å±€è®Šé‡
    project_id = st.secrets["project_id"]
    region = st.secrets["region"]
    
    main()